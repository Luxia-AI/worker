version: "3.9"

services:
  # Zookeeper for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: worker-zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - luxia-network
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka message broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: worker-kafka
    restart: always
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - luxia-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions.sh", "--bootstrap-server", "kafka:29092"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for realtime log streaming
  redis:
    image: redis:7-alpine
    container_name: worker-redis
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --dir /data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - luxia-network

  # FastAPI Worker Service
  worker:
    build: .
    container_name: worker
    restart: always
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    env_file:
      - .env
    environment:
      # Override Redis URL to use Docker service name
      REDIS_URL: "redis://redis:6379"
      LOG_DB_PATH: "/app/data/logs.db"
      # Kafka configuration - use kafka:29092 for internal communication
      KAFKA_BOOTSTRAP: "kafka:29092"
    ports:
      - "9000:9000"
    volumes:
      # Persist SQLite logs database in a directory
      - logs_data:/app/data
      # Cache downloaded embedding models (prevents re-download on container restart)
      - model_cache:/app/model_cache
    networks:
      - luxia-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/admin/logs?limit=1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  redis_data:
    driver: local
  logs_data:
    driver: local
  model_cache:
    driver: local

networks:
  luxia-network:
    driver: bridge
